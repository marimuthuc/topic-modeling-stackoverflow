{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_posts = pd.read_csv(\"../data/raw/so_tag_gpt.csv\")\n",
    "chat_gpt_posts = pd.read_csv(\"../data/raw/so_tag_chatgpt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 259 entries, 0 to 258\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Post Link         259 non-null    int64  \n",
      " 1   PostTypeId        259 non-null    int64  \n",
      " 2   OwnerUserId       259 non-null    int64  \n",
      " 3   Answer Link       43 non-null     float64\n",
      " 4   Title             259 non-null    object \n",
      " 5   Body              259 non-null    object \n",
      " 6   CreationDate      259 non-null    object \n",
      " 7   ClosedDate        13 non-null     object \n",
      " 8   LastEditDate      133 non-null    object \n",
      " 9   LastActivityDate  259 non-null    object \n",
      " 10  Tags              259 non-null    object \n",
      " 11  AnswerCount       259 non-null    int64  \n",
      " 12  CommentCount      259 non-null    int64  \n",
      " 13  Score             259 non-null    int64  \n",
      " 14  ViewCount         259 non-null    int64  \n",
      " 15  FavoriteCount     0 non-null      float64\n",
      " 16  PostTypeId.1      43 non-null     float64\n",
      " 17  OwnerUserId.1     43 non-null     float64\n",
      " 18  Body.1            43 non-null     object \n",
      " 19  CreationDate.1    43 non-null     object \n",
      " 20  CommentCount.1    43 non-null     float64\n",
      " 21  Score.1           43 non-null     float64\n",
      "dtypes: float64(6), int64(7), object(9)\n",
      "memory usage: 44.6+ KB\n"
     ]
    }
   ],
   "source": [
    "chat_gpt_posts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_posts = pd.concat([gpt_posts, chat_gpt_posts], ignore_index=False)\n",
    "df = so_posts.drop_duplicates(subset='Post Link', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 687 entries, 0 to 686\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Post Link         687 non-null    int64  \n",
      " 1   PostTypeId        687 non-null    int64  \n",
      " 2   OwnerUserId       683 non-null    float64\n",
      " 3   Answer Link       149 non-null    float64\n",
      " 4   Title             687 non-null    object \n",
      " 5   Body              687 non-null    object \n",
      " 6   CreationDate      687 non-null    object \n",
      " 7   ClosedDate        18 non-null     object \n",
      " 8   LastEditDate      368 non-null    object \n",
      " 9   LastActivityDate  687 non-null    object \n",
      " 10  Tags              687 non-null    object \n",
      " 11  AnswerCount       687 non-null    int64  \n",
      " 12  CommentCount      687 non-null    int64  \n",
      " 13  Score             687 non-null    int64  \n",
      " 14  ViewCount         687 non-null    int64  \n",
      " 15  FavoriteCount     27 non-null     float64\n",
      " 16  PostTypeId.1      149 non-null    float64\n",
      " 17  OwnerUserId.1     149 non-null    float64\n",
      " 18  Body.1            149 non-null    object \n",
      " 19  CreationDate.1    149 non-null    object \n",
      " 20  CommentCount.1    149 non-null    float64\n",
      " 21  Score.1           149 non-null    float64\n",
      "dtypes: float64(7), int64(6), object(9)\n",
      "memory usage: 118.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'Body'] = df['Body'].astype(str).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Code segments\n",
    "for index_label, row_series in df.iterrows():\n",
    "    soup = BeautifulSoup(df.at[index_label, 'Body'])\n",
    "    for tag in soup.find_all(['pre', 'blockquote', 'code']):\n",
    "        tag.replaceWith('')\n",
    "    df.at[index_label , 'Body'] = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I am trying to get the response from my gpt ap...\n",
       "1      I am trying to fine-tune the GPT model, and fo...\n",
       "2      I am trying to integrate the openAi API model ...\n",
       "3      I've been trying to upload a json file that I ...\n",
       "4      I am finetuning gpt2 on text classification wi...\n",
       "                             ...                        \n",
       "682    I want to create a self hosted LLM model that ...\n",
       "683    How do i add memory to RetrievalQA.from_chain_...\n",
       "684    I'm trying to use ChatGPT for my Telegram bot....\n",
       "685    When I use  parameter on https://api.openai.co...\n",
       "686    I have fine-tuned an  language model () and wa...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\r\", \" \", text)\n",
    "    text = re.sub(r\"<td>\", \" \", text)\n",
    "    text = re.sub(r\"</td>\", \" \", text)\n",
    "    text = re.sub(r\"<tr>\", \" \", text)\n",
    "    text = re.sub(r\"</tr>\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing URLs\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      i am trying to get the response from my gpt ap...\n",
       "1      i am trying to fine-tune the gpt model, and fo...\n",
       "2      i am trying to integrate the openai api model ...\n",
       "3      i have been trying to upload a json file that ...\n",
       "4      i am finetuning gpt2 on text classification wi...\n",
       "                             ...                        \n",
       "682    i want to create a self hosted llm model that ...\n",
       "683    how do i add memory to retrievalqa.from_chain_...\n",
       "684    i am trying to use chatgpt for my telegram bot...\n",
       "685    when i use parameter on  the memory is not per...\n",
       "686    i have fine-tuned an language model () and was...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing HTML Tags\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      i am trying to get the response from my gpt ap...\n",
       "1      i am trying to fine-tune the gpt model, and fo...\n",
       "2      i am trying to integrate the openai api model ...\n",
       "3      i have been trying to upload a json file that ...\n",
       "4      i am finetuning gpt2 on text classification wi...\n",
       "                             ...                        \n",
       "682    i want to create a self hosted llm model that ...\n",
       "683    how do i add memory to retrievalqa.from_chain_...\n",
       "684    i am trying to use chatgpt for my telegram bot...\n",
       "685    when i use parameter on  the memory is not per...\n",
       "686    i have fine-tuned an language model () and was...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      i am trying to get the response from my gpt ap...\n",
       "1      i am trying to fine-tune the gpt model, and fo...\n",
       "2      i am trying to integrate the openai api model ...\n",
       "3      i have been trying to upload a json file that ...\n",
       "4      i am finetuning gpt2 on text classification wi...\n",
       "                             ...                        \n",
       "682    i want to create a self hosted llm model that ...\n",
       "683    how do i add memory to retrievalqa.from_chain_...\n",
       "684    i am trying to use chatgpt for my telegram bot...\n",
       "685    when i use parameter on  the memory is not per...\n",
       "686    i have fine-tuned an language model () and was...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Emojis\n",
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuations\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "token=ToktokTokenizer()\n",
    "punct = '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^`{|}~-'\n",
    "def strip_list_noempty(mylist):\n",
    "    newlist = (item.strip() if hasattr(item, 'strip') else item for item in mylist)\n",
    "    return [item for item in newlist if item != '']\n",
    "def clean_punct(text): \n",
    "    words=token.tokenize(text)\n",
    "    punctuation_filtered = []\n",
    "    regex = re.compile('[%s]' % re.escape(punct))\n",
    "    for w in words:\n",
    "        if w in tags_features:\n",
    "            punctuation_filtered.append(w)\n",
    "        else:\n",
    "            punctuation_filtered.append(regex.sub('', w))\n",
    "  \n",
    "    filtered_list = strip_list_noempty(punctuation_filtered)\n",
    "        \n",
    "    return ' '.join(map(str, filtered_list))\n",
    "tags_features = pd.read_csv(\"../data/cleaned/freq_words.csv\", usecols = ['Tag'])\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: clean_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      i am trying to get the response from my gpt ap...\n",
       "1      i am trying to finetune the gpt model and for ...\n",
       "2      i am trying to integrate the openai api model ...\n",
       "3      i have been trying to upload a json file that ...\n",
       "4      i am finetuning gpt2 on text classification wi...\n",
       "                             ...                        \n",
       "682    i want to create a self hosted llm model that ...\n",
       "683    how do i add memory to retrievalqafrom_chain_t...\n",
       "684    i am trying to use chatgpt for my telegram bot...\n",
       "685    when i use parameter on the memory is not pers...\n",
       "686    i have finetuned an language model and was abl...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "#stop = stopwords.words('english')\n",
    "stop = ['after', 'afterwards','again','against', 'all', 'almost','alone','along',\n",
    "           'already',\n",
    "           'also',\n",
    "           'although',\n",
    "           'always',\n",
    "           'am',\n",
    "           'among',\n",
    "           'amongst',\n",
    "           'amoungst',\n",
    "           'amount',\n",
    "           'an',\n",
    "           'and',\n",
    "           'another',\n",
    "           'any',\n",
    "           'anyhow',\n",
    "           'anyone',\n",
    "           'anything',\n",
    "           'anyway',\n",
    "           'anywhere',\n",
    "           'are',\n",
    "           'around',\n",
    "           'as',\n",
    "           'at',\n",
    "           'back',\n",
    "           'be',\n",
    "           'became',\n",
    "           'because',\n",
    "           'become',\n",
    "           'becomes',\n",
    "           'becoming',\n",
    "           'been',\n",
    "           'before',\n",
    "           'beforehand',\n",
    "           'behind',\n",
    "           'being',\n",
    "           'below',\n",
    "           'beside',\n",
    "           'besides',\n",
    "           'between',\n",
    "           'beyond',\n",
    "           'bill',\n",
    "           'both',\n",
    "           'bottom',\n",
    "           'but',\n",
    "           'by',\n",
    "           'call',\n",
    "           'can',\n",
    "           'cannot',\n",
    "           'cant',\n",
    "           'co',\n",
    "           'con',\n",
    "           'could',\n",
    "           'couldnt',\n",
    "           'cry',\n",
    "           'de',\n",
    "           'describe',\n",
    "           'detail',\n",
    "           'do',\n",
    "           'done',\n",
    "           'down',\n",
    "           'due',\n",
    "           'during',\n",
    "           'each',\n",
    "           'eg',\n",
    "           'eight',\n",
    "           'either',\n",
    "           'eleven',\n",
    "           'else',\n",
    "           'elsewhere',\n",
    "           'empty',\n",
    "           'enough',\n",
    "           'etc',\n",
    "           'even',\n",
    "           'ever',\n",
    "           'every',\n",
    "           'everyone',\n",
    "           'everything',\n",
    "           'everywhere',\n",
    "           'except',\n",
    "           'few',\n",
    "           'fifteen',\n",
    "           'fifty',\n",
    "           'fill',\n",
    "           'find',\n",
    "           'fire',\n",
    "           'first',\n",
    "           'five',\n",
    "           'for',\n",
    "           'former',\n",
    "           'formerly',\n",
    "           'forty',\n",
    "           'found',\n",
    "           'four',\n",
    "           'from',\n",
    "           'front',\n",
    "           'full',\n",
    "           'further',\n",
    "           'get',\n",
    "           'give',\n",
    "           'go',\n",
    "           'had',\n",
    "           'has',\n",
    "           'have',\n",
    "           'he',\n",
    "           'hence',\n",
    "           'her',\n",
    "           'here',\n",
    "           'hereafter',\n",
    "           'hereby',\n",
    "           'herein',\n",
    "           'hereupon',\n",
    "           'hers',\n",
    "           'herself',\n",
    "           'him',\n",
    "           'himself',\n",
    "           'his',\n",
    "           'how',\n",
    "           'however',\n",
    "           'hundred',\n",
    "           'i',\n",
    "           'ie',\n",
    "           'if',\n",
    "           'in',\n",
    "           'inc',\n",
    "           'indeed',\n",
    "           'interest',\n",
    "           'into',\n",
    "           'is',\n",
    "           'it',\n",
    "           'its',\n",
    "           'itself',\n",
    "           'keep',\n",
    "           'last',\n",
    "           'latter',\n",
    "           'latterly',\n",
    "           'ltd',\n",
    "           'made',\n",
    "           'many',\n",
    "           'may',\n",
    "           'me',\n",
    "           'meanwhile',\n",
    "           'might',\n",
    "           'mill',\n",
    "           'mine',\n",
    "           'more',\n",
    "           'moreover',\n",
    "           'most',\n",
    "           'mostly',\n",
    "           'move',\n",
    "           'much',\n",
    "           'must',\n",
    "           'my',\n",
    "           'myself',\n",
    "           'name',\n",
    "           'namely',\n",
    "           'next',\n",
    "           'nine',\n",
    "           'of',\n",
    "           'off',\n",
    "           'often',\n",
    "           'on',\n",
    "           'once',\n",
    "           'one',\n",
    "           'only',\n",
    "           'onto',\n",
    "           'or',\n",
    "           'other',\n",
    "           'others',\n",
    "           'otherwise',\n",
    "           'our',\n",
    "           'ours',\n",
    "           'ourselves',\n",
    "           'out',\n",
    "           'over',\n",
    "           'own',\n",
    "           'part',\n",
    "           'per',\n",
    "           'perhaps',\n",
    "           'please',\n",
    "           'put',\n",
    "           'rather',\n",
    "           're',\n",
    "           'same',\n",
    "           'see',\n",
    "           'seem',\n",
    "           'seemed',\n",
    "           'seeming',\n",
    "           'seems',\n",
    "           'serious',\n",
    "           'several',\n",
    "           'she',\n",
    "           'should',\n",
    "           'show',\n",
    "           'side',\n",
    "           'since',\n",
    "           'sincere',\n",
    "           'six',\n",
    "           'sixty',\n",
    "           'so',\n",
    "           'some',\n",
    "           'somehow',\n",
    "           'someone',\n",
    "           'something',\n",
    "           'sometime',\n",
    "           'sometimes',\n",
    "           'somewhere',\n",
    "           'still',\n",
    "           'such',\n",
    "           'system',\n",
    "           'take',\n",
    "           'ten',\n",
    "           'than',\n",
    "           'that',\n",
    "           'the',\n",
    "           'their',\n",
    "           'them',\n",
    "           'themselves',\n",
    "           'then',\n",
    "           'thence',\n",
    "           'there',\n",
    "           'thereafter',\n",
    "           'thereby',\n",
    "           'therefore',\n",
    "           'therein',\n",
    "           'thereupon',\n",
    "           'these',\n",
    "           'they',\n",
    "           'thick',\n",
    "           'thin',\n",
    "           'third',\n",
    "           'this',\n",
    "           'those',\n",
    "           'though',\n",
    "           'three',\n",
    "           'through',\n",
    "           'throughout',\n",
    "           'thru',\n",
    "           'thus',\n",
    "           'to',\n",
    "           'together',\n",
    "           'too',\n",
    "           'top',\n",
    "           'toward',\n",
    "           'towards',\n",
    "           'twelve',\n",
    "           'twenty',\n",
    "           'two',\n",
    "           'un',\n",
    "           'under',\n",
    "           'until',\n",
    "           'up',\n",
    "           'upon',\n",
    "           'us',\n",
    "           'very',\n",
    "           'via',\n",
    "           'was',\n",
    "           'we',\n",
    "           'well',\n",
    "           'were',\n",
    "           'what',\n",
    "           'whatever',\n",
    "           'when',\n",
    "           'whence',\n",
    "           'whenever',\n",
    "           'where',\n",
    "           'whereafter',\n",
    "           'whereas',\n",
    "           'whereby',\n",
    "           'wherein',\n",
    "           'whereupon',\n",
    "           'wherever',\n",
    "           'whether',\n",
    "           'which',\n",
    "           'while',\n",
    "           'whither',\n",
    "           'who',\n",
    "           'whoever',\n",
    "           'whole',\n",
    "           'whom',\n",
    "           'whose',\n",
    "           'why',\n",
    "           'will',\n",
    "           'with',\n",
    "           'within',\n",
    "           'would',\n",
    "           'yet',\n",
    "           'you',\n",
    "           'your',\n",
    "           'yours',\n",
    "           'yourself',\n",
    "           'yourselves']\n",
    "\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "token=ToktokTokenizer()\n",
    "lemma=WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemitizeWords(text):\n",
    "    words=token.tokenize(text)\n",
    "    listLemma=[]\n",
    "    for w in words:\n",
    "        x=lemma.lemmatize(w, pos=\"v\")\n",
    "        listLemma.append(x)\n",
    "    return ' '.join(map(str, listLemma))\n",
    "\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: lemitizeWords(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      try response gpt api word word like chatgpt ge...\n",
       "1      try finetune gpt model 3 columns context quest...\n",
       "2      try integrate openai api model terminal enable...\n",
       "3      try upload a json file use fine tune gpt3 mode...\n",
       "4      finetuning gpt2 text classification huggingfac...\n",
       "                             ...                        \n",
       "682    want create a self host llm model able a conte...\n",
       "683    add memory retrievalqafrom_chain_type add a cu...\n",
       "684    try use chatgpt telegram bot use use textdavin...\n",
       "685    use parameter memory not persist across multip...\n",
       "686    finetuned language model able access model met...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing numbers\n",
    "number_pattern = r'[0-9]'\n",
    "df.loc[:, 'Body'] = df['Body'].apply(lambda x: re.sub(number_pattern, '', x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      try response gpt api word word like chatgpt ge...\n",
       "1      try finetune gpt model  columns context questi...\n",
       "2      try integrate openai api model terminal enable...\n",
       "3      try upload a json file use fine tune gpt model...\n",
       "4      finetuning gpt text classification huggingface...\n",
       "                             ...                        \n",
       "682    want create a self host llm model able a conte...\n",
       "683    add memory retrievalqafrom_chain_type add a cu...\n",
       "684    try use chatgpt telegram bot use use textdavin...\n",
       "685    use parameter memory not persist across multip...\n",
       "686    finetuned language model able access model met...\n",
       "Name: Body, Length: 687, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/cleaned/cleaned_data_second.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
